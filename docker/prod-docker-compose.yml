version: '3.4'
services:
  pipeline:
    image: jsokolowski/simbad-pipeline-server
    container_name: simbad-pipeline-server
    command: python entrypoint_api.py --port 8081 --debug
    env_file:
      - ./docker.env
    ports:
      - "8081:8081"
    volumes:
      - ../data:/usr/data
    depends_on:
      - redis
  worker:
    image: jsokolowski/simbad-pipeline-worker
    container_name: celery-worker
    links:
      - analyzer-server
    depends_on:
      - redis
    command: celery worker -A entrypoint_celery.celery --loglevel=info
    env_file:
      - ./docker.env
    volumes:
      - ../data:/usr/data
  analyzer-server:
    image: jsokolowski/simbad-analyzer-server
    container_name: simbad-analyzer-server
    command: python3 app.py --port 5000 --debug
    env_file:
      - ./docker.env
    volumes:
      - ../data:/usr/data
      - ./log4j.properties:/opt/spark-2.4.3-bin-hadoop2.7/conf/log4j.properties
    depends_on:
      - redis
    ports:
      - "5000:5000"
      - "4040:4040"
  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
  client:
    image: jsokolowski/simbad-client
    container_name: simbad-client
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    network_mode: host